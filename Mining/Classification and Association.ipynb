{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f7e82ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CLASSIFICATION ANALYSIS ===\n",
      "\n",
      "1. Decision Tree Classifier:\n",
      "- Saved decision tree visualization as decision_tree.png\n",
      "\n",
      "2. K-Nearest Neighbors (k=5):\n",
      "\n",
      "Decision Tree Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       0.90      0.90      0.90        10\n",
      "   virginica       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.93      0.93        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n",
      "\n",
      "KNN Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       0.91      1.00      0.95        10\n",
      "   virginica       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "\n",
      "Best model: KNN\n",
      "\n",
      "=== ASSOCIATION RULE MINING ===\n",
      "Generated 100 transactions\n",
      "\n",
      "Top 5 Association Rules:\n",
      "        antecedents      consequents  support  confidence      lift\n",
      "8   (diapers, milk)          (bread)     0.27    0.818182  1.386749\n",
      "11          (bread)  (diapers, milk)     0.27    0.457627  1.386749\n",
      "6      (milk, beer)          (bread)     0.25    0.757576  1.284027\n",
      "7           (bread)     (milk, beer)     0.25    0.423729  1.284027\n",
      "13    (eggs, bread)           (milk)     0.20    0.833333  1.282051\n",
      "- Saved rules as association_rules.csv\n",
      "\n",
      "Strongest rule: ['diapers', 'milk'] → ['bread']\n",
      "Lift: 1.39 (Confidence: 0.82)\n",
      "Business implication: These items should be placed together in store\n",
      "\n",
      "=== ALL TASKS COMPLETED ===\n",
      "Generated files:\n",
      "- decision_tree.png (classification)\n",
      "- association_rules.csv (market basket analysis)\n",
      "\n",
      "To install all required packages:\n",
      "pip install pandas scikit-learn matplotlib mlxtend\n"
     ]
    }
   ],
   "source": [
    "# ============ COMPLETE SOLUTION WITH ALL IMPORTS ============\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# ============ TASK 3A: CLASSIFICATION ============\n",
    "def perform_classification(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Complete classification task for Iris dataset\"\"\"\n",
    "    print(\"\\n=== CLASSIFICATION ANALYSIS ===\")\n",
    "    \n",
    "    # 1. Decision Tree Classifier\n",
    "    print(\"\\n1. Decision Tree Classifier:\")\n",
    "    dt = DecisionTreeClassifier(random_state=42)\n",
    "    dt.fit(X_train, y_train)\n",
    "    y_pred_dt = dt.predict(X_test)\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plot_tree(dt, feature_names=X_train.columns, \n",
    "              class_names=y_train.unique(), filled=True)\n",
    "    plt.savefig('decision_tree.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"- Saved decision tree visualization as decision_tree.png\")\n",
    "    \n",
    "    # 2. KNN Classifier\n",
    "    print(\"\\n2. K-Nearest Neighbors (k=5):\")\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_knn = knn.predict(X_test)\n",
    "    \n",
    "    # 3. Performance Comparison\n",
    "    print(\"\\nDecision Tree Performance:\")\n",
    "    print(classification_report(y_test, y_pred_dt))\n",
    "    \n",
    "    print(\"\\nKNN Performance:\")\n",
    "    print(classification_report(y_test, y_pred_knn))\n",
    "    \n",
    "    # Determine which performs better\n",
    "    if accuracy_score(y_test, y_pred_dt) > accuracy_score(y_test, y_pred_knn):\n",
    "        print(\"\\nBest model: Decision Tree\")\n",
    "    else:\n",
    "        print(\"\\nBest model: KNN\")\n",
    "\n",
    "# ============ TASK 3B: ASSOCIATION RULE MINING ============ \n",
    "def generate_transactions():\n",
    "    \"\"\"Generate synthetic market basket data\"\"\"\n",
    "    items = ['milk', 'bread', 'eggs', 'diapers', 'beer', \n",
    "             'cheese', 'wine', 'fruit', 'vegetables']\n",
    "    \n",
    "    # Create transactions with some patterns\n",
    "    transactions = []\n",
    "    for _ in range(100):\n",
    "        # Base transaction\n",
    "        transaction = random.sample(items, k=random.randint(2,5))\n",
    "        \n",
    "        # Add some common patterns\n",
    "        if random.random() > 0.7:\n",
    "            transaction.extend(['milk', 'bread'])\n",
    "        if random.random() > 0.8:\n",
    "            transaction.extend(['beer', 'diapers'])\n",
    "            \n",
    "        transactions.append(list(set(transaction)))  # Remove duplicates\n",
    "    \n",
    "    return transactions\n",
    "\n",
    "def perform_association_mining():\n",
    "    \"\"\"Perform association rule mining\"\"\"\n",
    "    print(\"\\n=== ASSOCIATION RULE MINING ===\")\n",
    "    \n",
    "    # Generate transaction data\n",
    "    transactions = generate_transactions()\n",
    "    print(f\"Generated {len(transactions)} transactions\")\n",
    "    \n",
    "    # Transform to one-hot encoded format\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(transactions).transform(transactions)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "    \n",
    "    # Find frequent itemsets\n",
    "    frequent_itemsets = apriori(df, min_support=0.2, use_colnames=True)\n",
    "    \n",
    "    # Generate association rules\n",
    "    rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.2)\n",
    "    rules = rules.sort_values('lift', ascending=False)\n",
    "    \n",
    "    # Save top 5 rules\n",
    "    top_rules = rules.head(5)\n",
    "    print(\"\\nTop 5 Association Rules:\")\n",
    "    print(top_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n",
    "    \n",
    "    # Save to CSV\n",
    "    top_rules.to_csv('association_rules.csv', index=False)\n",
    "    print(\"- Saved rules as association_rules.csv\")\n",
    "    \n",
    "    # Analyze strongest rule\n",
    "    best_rule = rules.iloc[0]\n",
    "    print(f\"\\nStrongest rule: {list(best_rule['antecedents'])} → {list(best_rule['consequents'])}\")\n",
    "    print(f\"Lift: {best_rule['lift']:.2f} (Confidence: {best_rule['confidence']:.2f})\")\n",
    "    print(\"Business implication: These items should be placed together in store\")\n",
    "\n",
    "# ============ MAIN EXECUTION ============\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess Iris data\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "    df['species'] = iris.target_names[iris.target]\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = MinMaxScaler()\n",
    "    df[iris.feature_names] = scaler.fit_transform(df[iris.feature_names])\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df[iris.feature_names], df['species'], test_size=0.2, random_state=42, stratify=df['species']\n",
    "    )\n",
    "    \n",
    "    # Run classification\n",
    "    perform_classification(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # Run association mining\n",
    "    perform_association_mining()\n",
    "    \n",
    "    print(\"\\n=== ALL TASKS COMPLETED ===\")\n",
    "    print(\"Generated files:\")\n",
    "    print(\"- decision_tree.png (classification)\")\n",
    "    print(\"- association_rules.csv (market basket analysis)\")\n",
    "    print(\"\\nTo install all required packages:\")\n",
    "    print(\"pip install pandas scikit-learn matplotlib mlxtend\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
