{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3770296c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Generating 1000 synthetic retail records\n",
      "INFO:__main__:Synthetic data generated with 1000 records\n",
      "INFO:__main__:Starting data transformation\n",
      "INFO:__main__:Data transformed. 518 records remaining after transformations\n",
      "INFO:__main__:Database schema created (tables dropped and recreated)\n",
      "INFO:__main__:Loaded 85 unique records into ProductDim\n",
      "INFO:__main__:Loaded 100 unique records into CustomerDim\n",
      "INFO:__main__:Loaded 285 unique records into TimeDim\n",
      "INFO:__main__:Loaded 518 records into SalesFact with valid foreign keys\n",
      "INFO:__main__:ETL process completed successfully\n"
     ]
    }
   ],
   "source": [
    "# etl_retail_fixed.py\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import logging\n",
    "import random\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class RetailETL:\n",
    "    def __init__(self):\n",
    "        self.db_file = 'retail_dw.db'\n",
    "        self.current_date = datetime(2025, 8, 12)  # As per exam instructions\n",
    "        \n",
    "        # Manual alternatives for Faker data\n",
    "        self.first_names = ['John', 'Jane', 'Robert', 'Emily', 'Michael', 'Sarah', 'David', 'Lisa']\n",
    "        self.last_names = ['Smith', 'Johnson', 'Williams', 'Brown', 'Jones', 'Miller', 'Davis']\n",
    "        self.cities = ['New York', 'London', 'Berlin', 'Paris', 'Tokyo', 'Sydney', 'Toronto']\n",
    "        self.companies = ['TechCorp', 'GlobalMart', 'HomeGoods', 'FashionCo', 'ElectroWorld']\n",
    "        \n",
    "    def generate_name(self):\n",
    "        return f\"{random.choice(self.first_names)} {random.choice(self.last_names)}\"\n",
    "    \n",
    "    def generate_synthetic_data(self, num_records=1000):\n",
    "        \"\"\"Generate synthetic retail data without Faker\"\"\"\n",
    "        logger.info(f\"Generating {num_records} synthetic retail records\")\n",
    "        \n",
    "        # Product categories and subcategories\n",
    "        categories = {\n",
    "            'Electronics': ['Smartphones', 'Laptops', 'Tablets', 'Accessories'],\n",
    "            'Clothing': ['Men', 'Women', 'Kids', 'Accessories'],\n",
    "            'Home': ['Furniture', 'Decor', 'Kitchen'],\n",
    "            'Books': ['Fiction', 'Non-Fiction', 'Educational'],\n",
    "            'Sports': ['Equipment', 'Apparel', 'Footwear']\n",
    "        }\n",
    "        \n",
    "        # Generate products - ensure unique product_ids\n",
    "        products = []\n",
    "        product_id = 1\n",
    "        for cat, subcats in categories.items():\n",
    "            for subcat in subcats:\n",
    "                for _ in range(5):  # 5 products per subcategory\n",
    "                    products.append({\n",
    "                        'product_id': product_id,\n",
    "                        'name': f\"{cat[:3]}-{subcat[:3]}-{product_id:03d}\",\n",
    "                        'category': cat,\n",
    "                        'subcategory': subcat,\n",
    "                        'supplier': random.choice(self.companies),\n",
    "                        'current_price': round(random.uniform(10, 500), 2)\n",
    "                    })\n",
    "                    product_id += 1\n",
    "        \n",
    "        # Generate customers - ensure unique customer_ids\n",
    "        customers = []\n",
    "        countries = ['UK', 'USA', 'Germany', 'France', 'Australia', 'Japan', 'Canada']\n",
    "        for customer_id in range(1, 101):  # 100 unique customers\n",
    "            customers.append({\n",
    "                'customer_id': customer_id,\n",
    "                'name': self.generate_name(),\n",
    "                'location': random.choice(self.cities),\n",
    "                'country': random.choice(countries),\n",
    "                'demographic_segment': random.choice(['Young', 'Adult', 'Senior', 'Student']),\n",
    "                'registration_date': (self.current_date - timedelta(days=random.randint(365, 1095))).strftime('%Y-%m-%d')\n",
    "            })\n",
    "        \n",
    "        # Generate sales transactions\n",
    "        data = []\n",
    "        for _ in range(num_records):\n",
    "            product = random.choice(products)\n",
    "            customer = random.choice(customers)\n",
    "            \n",
    "            # Generate random date within last 2 years\n",
    "            days_ago = random.randint(1, 730)\n",
    "            date = (self.current_date - timedelta(days=days_ago)).strftime('%Y-%m-%d')\n",
    "            \n",
    "            quantity = random.randint(1, 50)\n",
    "            unit_price = product['current_price'] * random.uniform(0.8, 1.2)\n",
    "            total_sales = quantity * unit_price\n",
    "            \n",
    "            data.append({\n",
    "                'InvoiceNo': f\"INV{random.randint(1000, 9999)}\",\n",
    "                'StockCode': f\"SKU{product['product_id']:04d}\",\n",
    "                'Description': product['name'],\n",
    "                'Quantity': quantity,\n",
    "                'InvoiceDate': date,\n",
    "                'UnitPrice': round(unit_price, 2),\n",
    "                'CustomerID': customer['customer_id'],\n",
    "                'Country': customer['country'],\n",
    "                'ProductID': product['product_id'],\n",
    "                'Category': product['category'],\n",
    "                'TotalSales': round(total_sales, 2)\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        logger.info(f\"Synthetic data generated with {len(df)} records\")\n",
    "        return df, products, customers\n",
    "    \n",
    "    def transform_data(self, df):\n",
    "        \"\"\"Transform the raw data\"\"\"\n",
    "        logger.info(\"Starting data transformation\")\n",
    "        \n",
    "        # Convert InvoiceDate to datetime\n",
    "        df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "        \n",
    "        # Handle missing values\n",
    "        df.dropna(subset=['CustomerID', 'UnitPrice'], inplace=True)\n",
    "        \n",
    "        # Handle outliers\n",
    "        df = df[(df['Quantity'] > 0) & (df['UnitPrice'] > 0)]\n",
    "        \n",
    "        # Filter for last year of data\n",
    "        one_year_ago = self.current_date - timedelta(days=365)\n",
    "        df = df[df['InvoiceDate'] >= one_year_ago]\n",
    "        \n",
    "        logger.info(f\"Data transformed. {len(df)} records remaining after transformations\")\n",
    "        return df\n",
    "    \n",
    "    def create_database(self):\n",
    "        \"\"\"Create SQLite database with schema\"\"\"\n",
    "        conn = sqlite3.connect(self.db_file)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Drop tables if they exist to start fresh\n",
    "        cursor.executescript('''\n",
    "        DROP TABLE IF EXISTS SalesFact;\n",
    "        DROP TABLE IF EXISTS CustomerDim;\n",
    "        DROP TABLE IF EXISTS ProductDim;\n",
    "        DROP TABLE IF EXISTS TimeDim;\n",
    "        \n",
    "        CREATE TABLE CustomerDim (\n",
    "            customer_id INTEGER PRIMARY KEY,\n",
    "            name TEXT NOT NULL,\n",
    "            location TEXT,\n",
    "            country TEXT,\n",
    "            demographic_segment TEXT,\n",
    "            registration_date DATE\n",
    "        );\n",
    "        \n",
    "        CREATE TABLE ProductDim (\n",
    "            product_id INTEGER PRIMARY KEY,\n",
    "            name TEXT NOT NULL,\n",
    "            category TEXT NOT NULL,\n",
    "            subcategory TEXT,\n",
    "            supplier TEXT,\n",
    "            current_price REAL\n",
    "        );\n",
    "        \n",
    "        CREATE TABLE TimeDim (\n",
    "            time_id INTEGER PRIMARY KEY,\n",
    "            date DATE NOT NULL,\n",
    "            day INTEGER NOT NULL,\n",
    "            month INTEGER NOT NULL,\n",
    "            quarter INTEGER NOT NULL,\n",
    "            year INTEGER NOT NULL,\n",
    "            is_weekend BOOLEAN NOT NULL\n",
    "        );\n",
    "        \n",
    "        CREATE TABLE SalesFact (\n",
    "            fact_sales_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            customer_id INTEGER NOT NULL,\n",
    "            product_id INTEGER NOT NULL,\n",
    "            time_id INTEGER NOT NULL,\n",
    "            quantity INTEGER NOT NULL,\n",
    "            unit_price REAL NOT NULL,\n",
    "            total_sales REAL NOT NULL,\n",
    "            FOREIGN KEY (customer_id) REFERENCES CustomerDim (customer_id),\n",
    "            FOREIGN KEY (product_id) REFERENCES ProductDim (product_id),\n",
    "            FOREIGN KEY (time_id) REFERENCES TimeDim (time_id)\n",
    "        );\n",
    "        \n",
    "        CREATE INDEX idx_sales_customer ON SalesFact(customer_id);\n",
    "        CREATE INDEX idx_sales_product ON SalesFact(product_id);\n",
    "        CREATE INDEX idx_sales_time ON SalesFact(time_id);\n",
    "        ''')\n",
    "        \n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        logger.info(\"Database schema created (tables dropped and recreated)\")\n",
    "    \n",
    "    def load_data(self, df, products, customers):\n",
    "        \"\"\"Load data into database with proper error handling\"\"\"\n",
    "        conn = sqlite3.connect(self.db_file)\n",
    "        \n",
    "        try:\n",
    "            # Load ProductDim - ensure no duplicates\n",
    "            product_dim = pd.DataFrame(products).drop_duplicates('product_id')\n",
    "            product_dim.to_sql('ProductDim', conn, if_exists='append', index=False)\n",
    "            logger.info(f\"Loaded {len(product_dim)} unique records into ProductDim\")\n",
    "            \n",
    "            # Load CustomerDim - ensure no duplicates\n",
    "            customer_dim = pd.DataFrame(customers).drop_duplicates('customer_id')\n",
    "            customer_dim.to_sql('CustomerDim', conn, if_exists='append', index=False)\n",
    "            logger.info(f\"Loaded {len(customer_dim)} unique records into CustomerDim\")\n",
    "            \n",
    "            # Load TimeDim\n",
    "            df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "            unique_dates = df['InvoiceDate'].dt.date.unique()\n",
    "            time_dim_data = []\n",
    "            \n",
    "            for date in unique_dates:\n",
    "                date_obj = datetime.strptime(str(date), '%Y-%m-%d')\n",
    "                time_dim_data.append({\n",
    "                    'time_id': int(date_obj.strftime('%Y%m%d')),\n",
    "                    'date': date,\n",
    "                    'day': date_obj.day,\n",
    "                    'month': date_obj.month,\n",
    "                    'quarter': (date_obj.month - 1) // 3 + 1,\n",
    "                    'year': date_obj.year,\n",
    "                    'is_weekend': date_obj.weekday() >= 5\n",
    "                })\n",
    "            \n",
    "            time_dim = pd.DataFrame(time_dim_data).drop_duplicates('time_id')\n",
    "            time_dim.to_sql('TimeDim', conn, if_exists='append', index=False)\n",
    "            logger.info(f\"Loaded {len(time_dim)} unique records into TimeDim\")\n",
    "            \n",
    "            # Load SalesFact\n",
    "            df['time_id'] = df['InvoiceDate'].dt.strftime('%Y%m%d').astype(int)\n",
    "            fact_data = df[['CustomerID', 'ProductID', 'time_id', 'Quantity', 'UnitPrice', 'TotalSales']]\n",
    "            fact_data.columns = ['customer_id', 'product_id', 'time_id', 'quantity', 'unit_price', 'total_sales']\n",
    "            \n",
    "            # Ensure foreign key constraints are satisfied\n",
    "            valid_customers = pd.read_sql('SELECT customer_id FROM CustomerDim', conn)['customer_id'].unique()\n",
    "            valid_products = pd.read_sql('SELECT product_id FROM ProductDim', conn)['product_id'].unique()\n",
    "            valid_times = pd.read_sql('SELECT time_id FROM TimeDim', conn)['time_id'].unique()\n",
    "            \n",
    "            fact_data = fact_data[\n",
    "                fact_data['customer_id'].isin(valid_customers) &\n",
    "                fact_data['product_id'].isin(valid_products) &\n",
    "                fact_data['time_id'].isin(valid_times)\n",
    "            ]\n",
    "            \n",
    "            fact_data.to_sql('SalesFact', conn, if_exists='append', index=False)\n",
    "            logger.info(f\"Loaded {len(fact_data)} records into SalesFact with valid foreign keys\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading data: {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            conn.close()\n",
    "    \n",
    "    def run_etl(self):\n",
    "        \"\"\"Execute full ETL pipeline\"\"\"\n",
    "        try:\n",
    "            # Extract\n",
    "            raw_data, products, customers = self.generate_synthetic_data(1000)\n",
    "            \n",
    "            # Transform\n",
    "            transformed_data = self.transform_data(raw_data)\n",
    "            \n",
    "            # Create database (drops existing tables)\n",
    "            self.create_database()\n",
    "            \n",
    "            # Load\n",
    "            self.load_data(transformed_data, products, customers)\n",
    "            \n",
    "            logger.info(\"ETL process completed successfully\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"ETL process failed: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    etl = RetailETL()\n",
    "    etl.run_etl()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
